#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# XGboost

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

from sklearn import metrics
# Predicted values
import global_variables as GB

# Importing the dataset
dataset = pd.read_csv('data.csv', sep = '|')
X = dataset.drop(['Name', 'md5', 'legitimate'], axis = 1).values
y = dataset['legitimate'].values

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)

# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

#Fitting xgboost to the training Set
from xgboost import XGBClassifier
classifier = XGBClassifier(max_depth=20, learning_rate=0.3, n_estimators=150)

X_train = np.nan_to_num(X_train)
y_train = np.nan_to_num(y_train)
classifier.fit(X_train, y_train)

#predict the test results
X_test = np.nan_to_num(X_test)

y_pred = classifier.predict(X_test)

#Makeing the confusion matrix
from sklearn.metrics import confusion_matrix
y_test = np.nan_to_num(y_test)
y_pred = np.nan_to_num(y_pred)

cm = confusion_matrix(y_test, y_pred)

#Applying K-Fold cross validation
from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)
# print(accuracies.mean())
# print(accuracies.std())

print(metrics.confusion_matrix(GB.y_act1, GB.y_pred1, labels=GB.labels1))
# Printing the precision and recall, among other metrics
print(metrics.classification_report(GB.y_act1, GB.y_pred1, labels=GB.labels1))


